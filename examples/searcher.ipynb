{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 検索機能のsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install qdrant-client\n",
    "!pip install langchain\n",
    "!pip install openai\n",
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "from qdrant_client import QdrantClient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'text-embedding-ada-002'\n",
    "model = OpenAIEmbeddings(model = model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Storage folder ../tools is already accessed by another instance of Qdrant client. If you require concurrent access, use Qdrant server instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBlockingIOError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/portalocker/portalocker.py:109\u001b[0m, in \u001b[0;36mlock\u001b[0;34m(file_, flags)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 109\u001b[0m     fcntl\u001b[39m.\u001b[39;49mflock(file_, flags)\n\u001b[1;32m    110\u001b[0m \u001b[39mexcept\u001b[39;00m locking_exceptions \u001b[39mas\u001b[39;00m exc_value:\n\u001b[1;32m    111\u001b[0m     \u001b[39m# The exception code varies on different systems so we'll catch\u001b[39;00m\n\u001b[1;32m    112\u001b[0m     \u001b[39m# every IO error\u001b[39;00m\n",
      "\u001b[0;31mBlockingIOError\u001b[0m: [Errno 11] Resource temporarily unavailable",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLockException\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/qdrant_client/local/qdrant_local.py:70\u001b[0m, in \u001b[0;36mQdrantLocal._load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flock \u001b[39m=\u001b[39m portalocker\u001b[39m.\u001b[39;49mlock(\n\u001b[1;32m     71\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flock_file,\n\u001b[1;32m     72\u001b[0m         portalocker\u001b[39m.\u001b[39;49mLockFlags\u001b[39m.\u001b[39;49mEXCLUSIVE \u001b[39m|\u001b[39;49m portalocker\u001b[39m.\u001b[39;49mLockFlags\u001b[39m.\u001b[39;49mNON_BLOCKING,\n\u001b[1;32m     73\u001b[0m     )\n\u001b[1;32m     74\u001b[0m \u001b[39mexcept\u001b[39;00m portalocker\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mLockException:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/portalocker/portalocker.py:113\u001b[0m, in \u001b[0;36mlock\u001b[0;34m(file_, flags)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[39mexcept\u001b[39;00m locking_exceptions \u001b[39mas\u001b[39;00m exc_value:\n\u001b[1;32m    111\u001b[0m     \u001b[39m# The exception code varies on different systems so we'll catch\u001b[39;00m\n\u001b[1;32m    112\u001b[0m     \u001b[39m# every IO error\u001b[39;00m\n\u001b[0;32m--> 113\u001b[0m     \u001b[39mraise\u001b[39;00m exceptions\u001b[39m.\u001b[39mLockException(exc_value, fh\u001b[39m=\u001b[39mfile_)\n",
      "\u001b[0;31mLockException\u001b[0m: [Errno 11] Resource temporarily unavailable",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../tools\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 4\u001b[0m qdrant \u001b[38;5;241m=\u001b[39m \u001b[43mQdrantClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/qdrant_client/qdrant_client.py:80\u001b[0m, in \u001b[0;36mQdrantClient.__init__\u001b[0;34m(self, location, url, port, grpc_port, prefer_grpc, https, api_key, prefix, timeout, host, path, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m     \u001b[39mif\u001b[39;00m path \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 80\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_client \u001b[39m=\u001b[39m QdrantLocal(location\u001b[39m=\u001b[39;49mpath)\n\u001b[1;32m     81\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     82\u001b[0m         \u001b[39mif\u001b[39;00m location \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m url \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/qdrant_client/local/qdrant_local.py:44\u001b[0m, in \u001b[0;36mQdrantLocal.__init__\u001b[0;34m(self, location)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flock_file: Optional[TextIOWrapper] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/qdrant_client/local/qdrant_local.py:75\u001b[0m, in \u001b[0;36mQdrantLocal._load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flock \u001b[39m=\u001b[39m portalocker\u001b[39m.\u001b[39mlock(\n\u001b[1;32m     71\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flock_file,\n\u001b[1;32m     72\u001b[0m         portalocker\u001b[39m.\u001b[39mLockFlags\u001b[39m.\u001b[39mEXCLUSIVE \u001b[39m|\u001b[39m portalocker\u001b[39m.\u001b[39mLockFlags\u001b[39m.\u001b[39mNON_BLOCKING,\n\u001b[1;32m     73\u001b[0m     )\n\u001b[1;32m     74\u001b[0m \u001b[39mexcept\u001b[39;00m portalocker\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mLockException:\n\u001b[0;32m---> 75\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m     76\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mStorage folder \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlocation\u001b[39m}\u001b[39;00m\u001b[39m is already accessed by another instance of Qdrant client.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     77\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m If you require concurrent access, use Qdrant server instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     78\u001b[0m     )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Storage folder ../tools is already accessed by another instance of Qdrant client. If you require concurrent access, use Qdrant server instead."
     ]
    }
   ],
   "source": [
    "# 一度の実行で良い\n",
    "path = '../tools'\n",
    "qdrant = QdrantClient(path=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'discription': 'Werver mode.qqqqqq', 'code': 'samqqqqqq'} score: 0.7390240945973159\n",
      "{'discription': 'Werver mode.qqqqqq', 'code': 'samqqqqqq'} score: 0.7390240945973159\n",
      "{'discription': 'Werver mode.qqqqqq', 'code': 'samqqqqqq'} score: 0.7390240945973159\n"
     ]
    }
   ],
   "source": [
    "query = 'All interaction with Qdrant takes place via the REST API.'\n",
    "\n",
    "hits = qdrant.search(\n",
    "    collection_name=\"tool_store\",\n",
    "    query_vector = embeddings.embed_query(query),\n",
    "    limit=3\n",
    ")\n",
    "for hit in hits:\n",
    "  print(hit.payload, \"score:\", hit.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(query: str, model):\n",
    "    hits = qdrant.search(\n",
    "        collection_name=\"tool_store\",\n",
    "        query_vector = embeddings.embed_query(query),\n",
    "        limit=5\n",
    "        )\n",
    "    \n",
    "    return hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'text-embedding-ada-002'\n",
    "model = OpenAIEmbeddings(model = model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'All interaction with Qdrant takes place via the REST API.'\n",
    "\n",
    "search_result = run(query, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Werver mode.qqqqqq'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_result[0].payload['discription']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'samqqqqqq'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_result[0].payload['code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Searcher():\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_model,\n",
    "        ):\n",
    "        self.embedding_model = embedding_model\n",
    "\n",
    "    def run(self, input):\n",
    "        query = f\"Helpful tools to do '{input}'\"\n",
    "\n",
    "        result = qdrant.search(\n",
    "            collection_name=\"tool_store\",\n",
    "            query_vector = self.embedding_model.embed_query(query),\n",
    "            limit=5\n",
    "            )\n",
    "            \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = 'All interaction with Qdrant takes place via the REST API.'\n",
    "model_name = 'text-embedding-ada-002'\n",
    "model = OpenAIEmbeddings(model = model_name)\n",
    "\n",
    "\n",
    "searcher = Searcher(embedding_model = model, input = input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = searcher.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discription:\n",
      "Werver mode.qqqqqq\n",
      "code:\n",
      "samqqqqqq\n",
      "------------------\n",
      "discription:\n",
      "Werver mode.qqqqqq\n",
      "code:\n",
      "samqqqqqq\n",
      "------------------\n",
      "discription:\n",
      "Werver mode.qqqqqq\n",
      "code:\n",
      "samqqqqqq\n",
      "------------------\n",
      "discription:\n",
      "Werver mode.qqqqqq\n",
      "code:\n",
      "samqqqqqq\n",
      "------------------\n",
      "discription:\n",
      "Werver mode.qqqqqq\n",
      "code:\n",
      "samqqqqqq\n",
      "------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "search_result = result\n",
    "\n",
    "executable_tasks = ''\n",
    "\n",
    "for i in range(len(result)):\n",
    "    disc = search_result[0].payload['discription']\n",
    "    code = search_result[0].payload['code']\n",
    "    executable_tasks += 'discription:' + '\\n' + disc +'\\n' + 'code:' +'\\n' + code + '\\n' + '------------------' + '\\n'\n",
    "    \n",
    "print(executable_tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decider():\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        ):\n",
    "        self.model = model\n",
    "\n",
    "    def run(self, input, search_result):\n",
    "        \n",
    "        executable_tasks = ''\n",
    "        \n",
    "        for i in range(len(search_result)):\n",
    "            disc = search_result[0].payload['discription']\n",
    "            code = search_result[0].payload['code']\n",
    "            \n",
    "        executable_tasks += 'discription:' + '\\n' + disc +'\\n' + 'code:' +'\\n' + code + '\\n' + '------------------' + '\\n'\n",
    "\n",
    "        prompt = \"\"\"\n",
    "        You are the agent that determines if the input task is executable.\n",
    "        Please check the description in the \"Task\" field and the main processing part of the code to be executed, and decide if the task is executable.\n",
    "        The task you are to perform is {input_}.\n",
    "        Answer \"Yes.\" if you can perform the task, or \"No.\" if you cannot.\n",
    "        Do not output anything other than \"Yes.\" or \"No.\".\n",
    "\n",
    "        What you can do is described below.         \n",
    "        -----------\n",
    "        {executable_tasks_}\n",
    "        \n",
    "        \"\"\".format(input_ = input, executable_tasks_ = executable_tasks)\n",
    "\n",
    "        responese = self.model(prompt)\n",
    "\n",
    "        if responese == \"Yes.\":\n",
    "            print('\\033[32m' + 'I do not need to create a tool to run it.\\n' + '\\033[0m')\n",
    "\n",
    "        elif responese == \"No.\":\n",
    "            print('\\033[32m' + 'I must create the tool before executing.\\n' + '\\033[0m')\n",
    "\n",
    "\n",
    "        return responese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mI must create the tool before executing.\n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'No.'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = OpenAI(temperature=0,model_name = 'gpt-3.5-turbo')\n",
    "#model = OpenAI(temperature=0,model_name = 'gpt-4')\n",
    "\n",
    "decider = Decider(model = model)\n",
    "\n",
    "input = 'training LightGBM model'\n",
    "\n",
    "search_result = result\n",
    "\n",
    "decider.run(input, search_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 取得したToolを全てappendしたToolのリストを作成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "from langchain.tools import BaseTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ScoredPoint(id=6, version=0, score=0.7487178988668953, payload={'discription': 'Werver mode.qqqqqq', 'code': 'samqqqqqq'}, vector=None),\n",
       " ScoredPoint(id=5, version=0, score=0.7487178988668953, payload={'discription': 'Werver mode.qqqqqq', 'code': 'samqqqqqq'}, vector=None),\n",
       " ScoredPoint(id=4, version=0, score=0.7487178988668953, payload={'discription': 'Werver mode.qqqqqq', 'code': 'samqqqqqq'}, vector=None),\n",
       " ScoredPoint(id=3, version=0, score=0.7486261024416454, payload={'discription': 'Werver mode.qqqqqq', 'code': 'samqqqqqq'}, vector=None),\n",
       " ScoredPoint(id=1, version=0, score=0.7442231889964104, payload={'discription': 'When you need to scale, simply switch to server mode.', 'code': 'sample'}, vector=None)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(search_result)):\n",
    "    disc = search_result[0].payload['discription']\n",
    "    code = search_result[0].payload['code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "agent = initialize_agent(tools, model, agent=\"zero-shot-react-description\", verbose=True)\n",
    "\n",
    "agent.run(input_prompt_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
