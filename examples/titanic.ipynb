{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation on titanic dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/fuyu-quant/CreateTool-AGI/blob/main/examples/titanic.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install git+https://github.com/fuyu-quant/CreateTool-AGI.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.1\n"
     ]
    }
   ],
   "source": [
    "from createtoolagi import CTAGI\n",
    "\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "#os.environ[\"OPENAI_API_KEY\"] = \"YOUR_API_KEY\"\n",
    "\n",
    "import pkg_resources\n",
    "package_name = \"createtoolagi\"  \n",
    "pkg = pkg_resources.get_distribution(package_name)\n",
    "print(pkg.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "data_set = ''\n",
    "with open('../data/learning.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        data_set += ','.join(row) + '\\n'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = \"\"\"\n",
    "{data_set_}\n",
    "------------------\n",
    "・Given the above data, predict \"survived\" using \"pclass,sex,age,sibsp,arch,fare,embarked,class,who,adult_male,deck,embark_town,alive,alone\" \n",
    "as input values between 0 and 1. \n",
    "・Predict the value of \"survived\" between 0 and 1. \n",
    "・Please write \"It is useful to receive a string and make a prediction.For example, a string like '2,male,27.0,0,0,13.0,S,Second,man,True,,Southampton,no,True' would be input.\" in the description of the code to be created.\n",
    "・The input data should be character strings as follows.\n",
    "------------------\n",
    "2,male,52.0,0,0,13.0,S,Second,man,True,,Southampton,no,True\n",
    "\"\"\".format(data_set_ = data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"3,male,32.0,0,0,7.75,Q,Third,man,True,,Queenstown,no,True\"\n",
    "\n",
    "validation_data = f\"Please use '{data}' as input data to predict survived.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = \"Make a prediction with the input data '3,male,32.0,0,0,7.75,Q,Third,man,True,,Queenstown,no,True'.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal GPT-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "gpt4 = OpenAI(temperature=0, model_name = 'gpt-4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt4(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r ../tools/titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from createtoolagi import CTAGI\n",
    "\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client import models\n",
    "\n",
    "base_model_name = 'gpt-4'\n",
    "#base_model_name = 'gpt-3.5-turbo'\n",
    "create_model_name = 'gpt-4'\n",
    "embegging_model_name = 'text-embedding-ada-002'\n",
    "\n",
    "qdrant = QdrantClient(path='../tools/titanic')\n",
    "qdrant.create_collection(collection_name =\"tool_store\", vectors_config=models.VectorParams(size=1536, distance=models.Distance.COSINE))\n",
    "\n",
    "ctagi = CTAGI(\n",
    "    base_model_name=base_model_name, \n",
    "    create_model_name=create_model_name, \n",
    "    embegging_model_name=embegging_model_name,\n",
    "    qdrant=qdrant\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Search tools.\n",
      "\u001b[32mSearch results：\n",
      "[]\n",
      "\u001b[0m\n",
      "> Decide if the task is executable.\n",
      "Response：No.\n",
      "\u001b[32mI must create the tool before executing.\n",
      "\u001b[0m\n",
      "Try:1\n",
      "> Create a tool.\n",
      "\u001b[32mCompleted!\n",
      "Created tool name：SurvivalPredictionTool\n",
      "\u001b[0m\n",
      "Created tool code: from langchain.tools import BaseTool\n",
      "\n",
      "class SurvivalPredictionTool(BaseTool):\n",
      "    name = \"SurvivalPredictionTool\"\n",
      "    description = \"It is useful to receive a string and make a prediction. For example, a string like '2,male,27.0,0,0,13.0,S,Second,man,True,,Southampton,no,True' would be input.\"\n",
      "\n",
      "    def _run(self, query: str) -> float:\n",
      "        \"Use the tool.\"\n",
      "        pclass, sex, age, sibsp, parch, fare, embarked, _class, who, adult_male, deck, embark_town, alive, alone = query.split(\",\")\n",
      "\n",
      "        # Convert string values to numerical values\n",
      "        sex = 1 if sex == \"male\" else 0\n",
      "        age = float(age) if age else 0\n",
      "        sibsp = int(sibsp)\n",
      "        parch = int(parch)\n",
      "        fare = float(fare)\n",
      "        embarked = {\"S\": 0, \"C\": 1, \"Q\": 2}.get(embarked, 0)\n",
      "        adult_male = 1 if adult_male == \"True\" else 0\n",
      "        alone = 1 if alone == \"True\" else 0\n",
      "\n",
      "        # Calculate survival score based on input values\n",
      "        survival_score = 0\n",
      "        survival_score += (3 - pclass) * 0.3\n",
      "        survival_score += (1 - sex) * 0.5\n",
      "        survival_score += (1 - adult_male) * 0.4\n",
      "        survival_score += (1 - alone) * 0.2\n",
      "\n",
      "        # Normalize survival score between 0 and 1\n",
      "        survival_score = max(0, min(survival_score, 1))\n",
      "\n",
      "        return survival_score\n",
      "\n",
      "    async def _arun(self, query: str) -> float:\n",
      "        \"Use the tool asynchronously.\"\n",
      "        raise NotImplementedError(\"SurvivalPredictionTool does not support async\")\n",
      "> Execute the task with the tool you created.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to use the SurvivalPredictionTool to make a prediction with the given input data.\n",
      "Action: SurvivalPredictionTool\n",
      "Action Input: 3,male,32.0,0,0,7.75,Q,Third,man,True,,Queenstown,no,True\u001b[0m\u001b[32mError occurred: unsupported operand type(s) for -: 'int' and 'str'\n",
      "\u001b[0m\n",
      "Try:2\n",
      "> Create a tool.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/createtoolagi/ctagi.py\", line 71, in run\n",
      "    self.executor.run_with_create_tool(validation_data, tool_code = tool_code)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/createtoolagi/executor.py\", line 62, in run_with_create_tool\n",
      "    agent.run(input)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/langchain/chains/base.py\", line 236, in run\n",
      "    return self(args[0], callbacks=callbacks)[self.output_keys[0]]\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/langchain/chains/base.py\", line 140, in __call__\n",
      "    raise e\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/langchain/chains/base.py\", line 134, in __call__\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/langchain/agents/agent.py\", line 905, in _call\n",
      "    next_step_output = self._take_next_step(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/langchain/agents/agent.py\", line 783, in _take_next_step\n",
      "    observation = tool.run(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/langchain/tools/base.py\", line 255, in run\n",
      "    raise e\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/langchain/tools/base.py\", line 251, in run\n",
      "    else self._run(*tool_args, **tool_kwargs)\n",
      "  File \"<string>\", line 23, in _run\n",
      "TypeError: unsupported operand type(s) for -: 'int' and 'str'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mCompleted!\n",
      "Created tool name：SurvivalPredictionTool\n",
      "\u001b[0m\n",
      "Created tool code: from langchain.tools import BaseTool\n",
      "\n",
      "class SurvivalPredictionTool(BaseTool):\n",
      "    name = \"SurvivalPredictionTool\"\n",
      "    description = \"It is useful to receive a string and make a prediction. For example, a string like '2,male,27.0,0,0,13.0,S,Second,man,True,,Southampton,no,True' would be input.\"\n",
      "\n",
      "    def _run(self, query: str) -> float:\n",
      "        \"Use the tool.\"\n",
      "        pclass, sex, age, sibsp, parch, fare, embarked, _class, who, adult_male, deck, embark_town, alive, alone = query.split(\",\")\n",
      "\n",
      "        # Convert string values to numerical values\n",
      "        pclass = int(pclass)\n",
      "        sex = 1 if sex == \"male\" else 0\n",
      "        age = float(age) if age else 0\n",
      "        sibsp = int(sibsp)\n",
      "        parch = int(parch)\n",
      "        fare = float(fare)\n",
      "        embarked = {\"S\": 0, \"C\": 1, \"Q\": 2}.get(embarked, 0)\n",
      "        adult_male = 1 if adult_male == \"True\" else 0\n",
      "        alone = 1 if alone == \"True\" else 0\n",
      "\n",
      "        # Calculate survival score based on input values\n",
      "        survival_score = 0\n",
      "        survival_score += (3 - pclass) * 0.3\n",
      "        survival_score += (1 - sex) * 0.5\n",
      "        survival_score += (1 - adult_male) * 0.4\n",
      "        survival_score += (1 - alone) * 0.2\n",
      "\n",
      "        # Normalize survival score between 0 and 1\n",
      "        survival_score = max(0, min(survival_score, 1))\n",
      "\n",
      "        return survival_score\n",
      "\n",
      "    async def _arun(self, query: str) -> float:\n",
      "        \"Use the tool asynchronously.\"\n",
      "        raise NotImplementedError(\"SurvivalPredictionTool does not support async\")\n",
      "> Execute the task with the tool you created.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to use the SurvivalPredictionTool to make a prediction with the given input data.\n",
      "Action: SurvivalPredictionTool\n",
      "Action Input: 3,male,32.0,0,0,7.75,Q,Third,man,True,,Queenstown,no,True\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m0\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
      "Final Answer: 0\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "> Save a tool.\n"
     ]
    }
   ],
   "source": [
    "ctagi.run(training_data = training_data, validation_data = validation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"3,male,32.0,0,0,7.75,Q,Third,man,True,,Queenstown,no,True\"\n",
    "\n",
    "validation_data = f\"Please use '{data}' as input data to predict survived.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = \"Make a prediction with the input data '3,male,32.0,0,0,7.75,Q,Third,man,True,,Queenstown,no,True'.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = \"What is the predicted value when the input data is '3,male,32.0,0,0,7.75,Q,Third,man,True,,Queenstown,no,True'?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Search tools.\n",
      "\u001b[32mSearch results：\n",
      "[ScoredPoint(id=1, version=0, score=0.8014364914743698, payload={'description': \"It is useful to receive a string and make a prediction. For example, a string like '2,male,27.0,0,0,13.0,S,Second,man,True,,Southampton,no,True' would be input.\", 'code': 'from langchain.tools import BaseTool\\n\\nclass SurvivalPredictionTool(BaseTool):\\n    name = \"SurvivalPredictionTool\"\\n    description = \"It is useful to receive a string and make a prediction. For example, a string like \\'2,male,27.0,0,0,13.0,S,Second,man,True,,Southampton,no,True\\' would be input.\"\\n\\n    def _run(self, query: str) -> float:\\n        \"Use the tool.\"\\n        pclass, sex, age, sibsp, parch, fare, embarked, _class, who, adult_male, deck, embark_town, alive, alone = query.split(\",\")\\n\\n        # Convert string values to numerical values\\n        pclass = int(pclass)\\n        sex = 1 if sex == \"male\" else 0\\n        age = float(age) if age else 0\\n        sibsp = int(sibsp)\\n        parch = int(parch)\\n        fare = float(fare)\\n        embarked = {\"S\": 0, \"C\": 1, \"Q\": 2}.get(embarked, 0)\\n        adult_male = 1 if adult_male == \"True\" else 0\\n        alone = 1 if alone == \"True\" else 0\\n\\n        # Calculate survival score based on input values\\n        survival_score = 0\\n        survival_score += (3 - pclass) * 0.3\\n        survival_score += (1 - sex) * 0.5\\n        survival_score += (1 - adult_male) * 0.4\\n        survival_score += (1 - alone) * 0.2\\n\\n        # Normalize survival score between 0 and 1\\n        survival_score = max(0, min(survival_score, 1))\\n\\n        return survival_score\\n\\n    async def _arun(self, query: str) -> float:\\n        \"Use the tool asynchronously.\"\\n        raise NotImplementedError(\"SurvivalPredictionTool does not support async\")', 'tool_name': 'SurvivalPredictionTool'}, vector=None)]\n",
      "\u001b[0m\n",
      "> Decide if the task is executable.\n",
      "Response：Yes.\n",
      "\u001b[32mI do not need to create a tool to run it.\n",
      "\u001b[0m\n",
      "> Execute the task.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to know the input question to answer it.\n",
      "Final Answer: Please provide the input question.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ctagi.run(training_data = training_data, validation_data = validation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.tools import BaseTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurvivalPredictionTool(BaseTool):\n",
    "    name = \"SurvivalPredictionTool\"\n",
    "    description = \"used for prediction. The input is a comma-separated string. For example, it receives inputs such as '2,male,27.0,0,0,13.0,S,Second,man,True,,Southampton,no,True'.\"\n",
    "\n",
    "    def _run(self, query: str) -> float:\n",
    "        \"Use the tool.\"\n",
    "        pclass, sex, age, sibsp, parch, fare, embarked, _class, who, adult_male, deck, embark_town, alive, alone = query.split(\",\")\n",
    "\n",
    "        # Convert string values to numerical values\n",
    "        pclass = int(pclass)\n",
    "        sex = 1 if sex == \"male\" else 0\n",
    "        age = float(age) if age else 0\n",
    "        sibsp = int(sibsp)\n",
    "        parch = int(parch)\n",
    "        fare = float(fare)\n",
    "        embarked = {\"S\": 0, \"C\": 1, \"Q\": 2}.get(embarked, 0)\n",
    "        _class = {\"First\": 1, \"Second\": 2, \"Third\": 3}.get(_class, 0)\n",
    "        who = {\"man\": 1, \"woman\": 2, \"child\": 3}.get(who, 0)\n",
    "        adult_male = 1 if adult_male == \"True\" else 0\n",
    "        deck = {\"A\": 1, \"B\": 2, \"C\": 3, \"D\": 4, \"E\": 5, \"F\": 6, \"G\": 7}.get(deck, 0)\n",
    "        embark_town = {\"Southampton\": 1, \"Cherbourg\": 2, \"Queenstown\": 3}.get(embark_town, 0)\n",
    "        alive = 1 if alive == \"yes\" else 0\n",
    "        alone = 1 if alone == \"True\" else 0\n",
    "\n",
    "        # Calculate survival score based on input values\n",
    "        survival_score = 0\n",
    "        survival_score += pclass * 0.1\n",
    "        survival_score += sex * 0.3\n",
    "        survival_score += age * 0.05\n",
    "        survival_score += sibsp * 0.05\n",
    "        survival_score += parch * 0.05\n",
    "        survival_score += fare * 0.1\n",
    "        survival_score += embarked * 0.1\n",
    "        survival_score += _class * 0.1\n",
    "        survival_score += who * 0.1\n",
    "        survival_score += adult_male * 0.1\n",
    "        survival_score += deck * 0.1\n",
    "        survival_score += embark_town * 0.1\n",
    "        survival_score += alive * 0.3\n",
    "        survival_score += alone * 0.1\n",
    "\n",
    "        # Normalize survival score between 0 and 1\n",
    "        survival_score = survival_score / 2.0\n",
    "\n",
    "        return survival_score\n",
    "\n",
    "    async def _arun(self, query: str) -> float:\n",
    "        \"Use the tool asynchronously.\"\n",
    "        raise NotImplementedError(\"SurvivalPredictionTool does not support async\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurvivalPredictionTool(BaseTool):\n",
    "    name = \"SurvivalPredictionTool\"\n",
    "    description = \"It is useful to receive a string and make a prediction.For example, a string like '2,male,27.0,0,0,13.0,S,Second,man,True,,Southampton,no,True' would be input.\"\n",
    "\n",
    "    def _run(self, query: str) -> float:\n",
    "        \"Use the tool.\"\n",
    "        pclass, sex, age, sibsp, parch, fare, embarked, _class, who, adult_male, deck, embark_town, alive, alone = query.split(\",\")\n",
    "\n",
    "        # Convert input values to appropriate data types\n",
    "        pclass = int(pclass)\n",
    "        age = float(age) if age else None\n",
    "        sibsp = int(sibsp)\n",
    "        parch = int(parch)\n",
    "        fare = float(fare)\n",
    "        adult_male = adult_male.lower() == \"true\"\n",
    "        alone = alone.lower() == \"true\"\n",
    "\n",
    "        # Define weights for each feature\n",
    "        weights = {\n",
    "            \"pclass\": -0.15,\n",
    "            \"sex\": 0.5,\n",
    "            \"age\": -0.01,\n",
    "            \"sibsp\": -0.05,\n",
    "            \"parch\": 0.02,\n",
    "            \"fare\": 0.001,\n",
    "            \"embarked\": 0.1,\n",
    "            \"adult_male\": -0.3,\n",
    "            \"alone\": -0.1\n",
    "        }\n",
    "\n",
    "        # Calculate the prediction score\n",
    "        score = 0\n",
    "        score += weights[\"pclass\"] * pclass\n",
    "        score += weights[\"sex\"] * (1 if sex.lower() == \"female\" else 0)\n",
    "        score += weights[\"age\"] * (age if age else 0)\n",
    "        score += weights[\"sibsp\"] * sibsp\n",
    "        score += weights[\"parch\"] * parch\n",
    "        score += weights[\"fare\"] * fare\n",
    "        score += weights[\"embarked\"] * (1 if embarked.lower() == \"c\" else 0)\n",
    "        score += weights[\"adult_male\"] * adult_male\n",
    "        score += weights[\"alone\"] * alone\n",
    "\n",
    "        # Normalize the score to a value between 0 and 1\n",
    "        prediction = 1 / (1 + pow(2.71828, -score))\n",
    "\n",
    "        return prediction\n",
    "\n",
    "    async def _arun(self, query: str) -> float:\n",
    "        \"Use the tool asynchronously.\"\n",
    "        raise NotImplementedError(\"SurvivalPredictionTool does not support async\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SurvivalPredictionTool(name='SurvivalPredictionTool', description=\"It is useful to receive a string and make a prediction.For example, a string like '2,male,27.0,0,0,13.0,S,Second,man,True,,Southampton,no,True' would be input.\", args_schema=None, return_direct=False, verbose=False, callbacks=None, callback_manager=None)]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools =[]\n",
    "\n",
    "SurvivalPredictionTool = SurvivalPredictionTool()\n",
    "tools.append(SurvivalPredictionTool)\n",
    "\n",
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = \"Make a prediction with the input data '2,male,27.0,0,0,13.0,S,Second,man,True,,Southampton,no,True'.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4 = OpenAI(temperature=0, model_name = 'gpt-4')\n",
    "\n",
    "agent = initialize_agent(\n",
    "            tools = tools, \n",
    "            llm = gpt4, \n",
    "            agent=\"zero-shot-react-description\", \n",
    "            verbose=True\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to use the SurvivalPredictionTool to make a prediction with the given input data.\n",
      "Action: SurvivalPredictionTool\n",
      "Action Input: 2,male,27.0,0,0,13.0,S,Second,man,True,,Southampton,no,True\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m0.27747937578602305\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
      "Final Answer: 0.27747937578602305\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "0.27747937578602305\n"
     ]
    }
   ],
   "source": [
    "output = agent.run(validation_data)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
